{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5405d6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/23ucc611/miniconda3/envs/ml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU name: Tesla V100-SXM2-32GB\n",
      "Total GPU mem (GB): 31.7325439453125\n",
      "timm version: 1.0.21\n",
      "PyTorch: 2.6.0+cu124\n",
      "PyTorch: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "CUDA device: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import os, sys, math, time, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\" \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset, Subset, random_split\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "SEED = 42\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Total GPU mem (GB):\", torch.cuda.get_device_properties(0).total_memory / (1024**3))\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"timm version:\", timm.__version__)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57151d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset root (BASE_DIR): /home/23ucc611/SWE/Poaching/dataset\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 ‚Äî imports and paths (edit DATA_YAML if your yaml is elsewhere)\n",
    "import os, sys, shutil, glob, yaml, re\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "DATA_YAML = \"/home/23ucc611/SWE/Poaching/dataset/data.yaml\"   # <--- change if needed\n",
    "assert os.path.exists(DATA_YAML), f\"data.yaml not found at {DATA_YAML}\"\n",
    "BASE_DIR = str(Path(DATA_YAML).resolve().parent)   # dataset root (yaml parent)\n",
    "print(\"Dataset root (BASE_DIR):\", BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea39402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 'train/images',\n",
       " 'val': 'valid/images',\n",
       " 'test': 'test/images',\n",
       " 'names': {0: 'Antelope',\n",
       "  1: 'Badger',\n",
       "  2: 'Bat',\n",
       "  3: 'Bear',\n",
       "  4: 'Bike',\n",
       "  5: 'Binocular',\n",
       "  6: 'Bison',\n",
       "  7: 'Boar',\n",
       "  8: 'Car',\n",
       "  9: 'Cheetah',\n",
       "  10: 'Chimpanzee',\n",
       "  11: 'Coyote',\n",
       "  12: 'Deer',\n",
       "  13: 'Dog',\n",
       "  14: 'Donkey',\n",
       "  15: 'Duck',\n",
       "  16: 'Eagle',\n",
       "  17: 'Elephant',\n",
       "  18: 'Flamingo',\n",
       "  19: 'Fox',\n",
       "  20: 'Giraffe',\n",
       "  21: 'Goat',\n",
       "  22: 'Goose',\n",
       "  23: 'Gorilla',\n",
       "  24: 'Hare',\n",
       "  25: 'Hedgehog',\n",
       "  26: 'Helicopter',\n",
       "  27: 'Hippopotamus',\n",
       "  28: 'Hornbill',\n",
       "  29: 'Horse',\n",
       "  30: 'Humming Bird',\n",
       "  31: 'Hunter',\n",
       "  32: 'Hyena',\n",
       "  33: 'Jeep',\n",
       "  34: 'Kangaroo',\n",
       "  35: 'Knife',\n",
       "  36: 'Koala',\n",
       "  37: 'Leopard',\n",
       "  38: 'Lion',\n",
       "  39: 'Lizard',\n",
       "  40: 'Mouse',\n",
       "  41: 'Okapi',\n",
       "  42: 'Orangutan',\n",
       "  43: 'Otter',\n",
       "  44: 'Owl',\n",
       "  45: 'Ox',\n",
       "  46: 'Panda',\n",
       "  47: 'Parrot',\n",
       "  48: 'Pig',\n",
       "  49: 'Pigeon',\n",
       "  50: 'Pistol',\n",
       "  51: 'Porcupine',\n",
       "  52: 'Possum',\n",
       "  53: 'Raccoon',\n",
       "  54: 'Reindeer',\n",
       "  55: 'Rifle',\n",
       "  56: 'Rinoceros',\n",
       "  57: 'Rope',\n",
       "  58: 'Sandpiper',\n",
       "  59: 'Sheep',\n",
       "  60: 'Snake',\n",
       "  61: 'Sparrow',\n",
       "  62: 'Squirrel',\n",
       "  63: 'Tiger',\n",
       "  64: 'Truck',\n",
       "  65: 'Turkey',\n",
       "  66: 'Van',\n",
       "  67: 'Wolf',\n",
       "  68: 'Wombat',\n",
       "  69: 'Woodpecker',\n",
       "  70: 'X-Bow',\n",
       "  71: 'Zebra'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2 ‚Äî parse data.yaml to get splits & class names\n",
    "with open(DATA_YAML, 'r') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5911a5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images: /home/23ucc611/SWE/Poaching/dataset/train/images\n",
      "train labels: /home/23ucc611/SWE/Poaching/dataset/train/labels\n",
      "val images  : /home/23ucc611/SWE/Poaching/dataset/valid/images\n",
      "val labels  : /home/23ucc611/SWE/Poaching/dataset/valid/labels\n",
      "test images : /home/23ucc611/SWE/Poaching/dataset/test/images\n",
      "test labels : /home/23ucc611/SWE/Poaching/dataset/test/labels\n",
      "Num classes listed in data.yaml: 72\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 ‚Äî infer split image/label directories (works for common layouts)\n",
    "# tries to detect train/val/test or train/valid/test subfolders from yaml paths\n",
    "def resolve_split_paths(field):\n",
    "    p = data.get(field)\n",
    "    if p is None: \n",
    "        return None\n",
    "    p = str(Path(p))\n",
    "    if not os.path.isabs(p):\n",
    "        p = os.path.join(BASE_DIR, p)\n",
    "    # common Roboflow layout: train/images, train/labels\n",
    "    parent = Path(p).parent\n",
    "    images = p if 'images' in p else os.path.join(parent, 'images')\n",
    "    labels = os.path.join(parent, 'labels')\n",
    "    return str(Path(images)), str(Path(labels))\n",
    "\n",
    "train_images_dir, train_labels_dir = resolve_split_paths('train')\n",
    "val_images_dir, val_labels_dir = resolve_split_paths('val') or resolve_split_paths('valid')\n",
    "test_images_dir, test_labels_dir = resolve_split_paths('test') or (None, None)\n",
    "\n",
    "print(\"train images:\", train_images_dir)\n",
    "print(\"train labels:\", train_labels_dir)\n",
    "print(\"val images  :\", val_images_dir)\n",
    "print(\"val labels  :\", val_labels_dir)\n",
    "print(\"test images :\", test_images_dir)\n",
    "print(\"test labels :\", test_labels_dir)\n",
    "\n",
    "CLASS_NAMES = data.get('names') or data.get('names', {})\n",
    "# data may store names as list or dict\n",
    "names_list = CLASS_NAMES\n",
    "print(\"Num classes listed in data.yaml:\", len(names_list) if names_list else \"unknown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633fc1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts -> train imgs: 4182 train lbls: 4182\n",
      "counts -> val   imgs: 905 val   lbls: 905\n",
      "counts -> test  imgs: 898 test  lbls: 898\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 ‚Äî helper: find images and labels and normalize names\n",
    "# Supported image extensions:\n",
    "IMG_EXTS = {'.jpg','.jpeg','.png','.bmp','.tif','.tiff','.webp','.gif'}\n",
    "LABEL_EXTS = {'.txt'}   # YOLO label files\n",
    "\n",
    "def list_files(dir_path, exts):\n",
    "    if dir_path is None: return []\n",
    "    d = Path(dir_path)\n",
    "    if not d.exists():\n",
    "        return []\n",
    "    return [str(p) for p in d.rglob('*') if p.suffix.lower() in exts]\n",
    "\n",
    "def normalize_filename(path):\n",
    "    # replace spaces and problematic chars\n",
    "    p = Path(path)\n",
    "    new_name = re.sub(r'[\\s]+', '_', p.name)  # replace spaces\n",
    "    new_name = re.sub(r'[^0-9A-Za-z_.\\-]', '', new_name)  # remove weird chars\n",
    "    return str(p.with_name(new_name))\n",
    "\n",
    "# collect\n",
    "train_imgs = list_files(train_images_dir, IMG_EXTS)\n",
    "train_lbls = list_files(train_labels_dir, LABEL_EXTS)\n",
    "val_imgs   = list_files(val_images_dir, IMG_EXTS)\n",
    "val_lbls   = list_files(val_labels_dir, LABEL_EXTS)\n",
    "test_imgs  = list_files(test_images_dir, IMG_EXTS) if test_images_dir else []\n",
    "test_lbls  = list_files(test_labels_dir, LABEL_EXTS) if test_labels_dir else []\n",
    "\n",
    "print(\"counts -> train imgs:\", len(train_imgs), \"train lbls:\", len(train_lbls))\n",
    "print(\"counts -> val   imgs:\", len(val_imgs), \"val   lbls:\", len(val_lbls))\n",
    "print(\"counts -> test  imgs:\", len(test_imgs), \"test  lbls:\", len(test_lbls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19bad959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed files count: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 ‚Äî rename files in-place to normalized names (images and labels)\n",
    "# WARNING: this modifies filenames. Make a backup if you need to preserve originals.\n",
    "def batch_rename(file_list):\n",
    "    renamed = []\n",
    "    for p in file_list:\n",
    "        newp = normalize_filename(p)\n",
    "        if newp != p:\n",
    "            # ensure we don't overwrite existing file\n",
    "            if os.path.exists(newp):\n",
    "                # add suffix if collision\n",
    "                base = str(Path(newp).with_suffix(''))\n",
    "                sfx = 1\n",
    "                while os.path.exists(f\"{base}_{sfx}{Path(newp).suffix}\"):\n",
    "                    sfx += 1\n",
    "                newp = f\"{base}_{sfx}{Path(newp).suffix}\"\n",
    "            shutil.move(p, newp)\n",
    "            renamed.append((p, newp))\n",
    "    return renamed\n",
    "\n",
    "renamed = []\n",
    "renamed += batch_rename(train_imgs)\n",
    "renamed += batch_rename(train_lbls)\n",
    "renamed += batch_rename(val_imgs)\n",
    "renamed += batch_rename(val_lbls)\n",
    "renamed += batch_rename(test_imgs)\n",
    "renamed += batch_rename(test_lbls)\n",
    "print(\"Renamed files count:\", len(renamed))\n",
    "if renamed:\n",
    "    print(\"Sample renames:\", renamed[:10])\n",
    "# refresh lists after rename\n",
    "train_imgs = list_files(train_images_dir, IMG_EXTS)\n",
    "train_lbls = list_files(train_labels_dir, LABEL_EXTS)\n",
    "val_imgs = list_files(val_images_dir, IMG_EXTS)\n",
    "val_lbls = list_files(val_labels_dir, LABEL_EXTS)\n",
    "test_imgs = list_files(test_images_dir, IMG_EXTS)\n",
    "test_lbls = list_files(test_labels_dir, LABEL_EXTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76703e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN -> only-images (no label): 0\n",
      "TRAIN -> only-labels (no image): 0\n",
      "TRAIN -> matched pairs: 905\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 ‚Äî match images <-> labels by base name, fix common mismatches (uppercase extensions, .jpeg vs .jpg), and report\n",
    "def base(filepath):\n",
    "    return Path(filepath).stem\n",
    "\n",
    "def index_by_basename(file_list):\n",
    "    d = {}\n",
    "    for p in file_list:\n",
    "        d[base(p)] = p\n",
    "    return d\n",
    "\n",
    "def find_matches(img_list, lbl_list):\n",
    "    imgs_idx = index_by_basename(img_list)\n",
    "    lbls_idx = index_by_basename(lbl_list)\n",
    "    img_only = sorted([imgs_idx[k] for k in imgs_idx.keys() - lbls_idx.keys()])\n",
    "    lbl_only = sorted([lbls_idx[k] for k in lbls_idx.keys() - imgs_idx.keys()])\n",
    "    both = sorted([imgs_idx[k] for k in imgs_idx.keys() & lbls_idx.keys()])\n",
    "    return img_only, lbl_only, both\n",
    "\n",
    "img_only, lbl_only, both = (\n",
    "    *find_matches(train_imgs, train_lbls),\n",
    ")\n",
    "print(\"TRAIN -> only-images (no label):\", len(img_only))\n",
    "print(\"TRAIN -> only-labels (no image):\", len(lbl_only))\n",
    "print(\"TRAIN -> matched pairs:\", len(both))\n",
    "if len(img_only)>0:\n",
    "    print(\"sample img-only:\", img_only[:5])\n",
    "if len(lbl_only)>0:\n",
    "    print(\"sample lbl-only:\", lbl_only[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c2154f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty label creation skipped. (set CREATE_EMPTY_LABELS=True to enable)\n",
      "TRAIN image/label counts match exactly.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 ‚Äî print top-level sanity and optionally create missing blank label files for images with no labels\n",
    "# (create blank label if you want the model to treat it as 'no object' rather than fail)\n",
    "CREATE_EMPTY_LABELS = False  # set True to auto-create .txt files for images missing labels (caution)\n",
    "if CREATE_EMPTY_LABELS and img_only:\n",
    "    for im_path in img_only:\n",
    "        lbl_path = os.path.join(train_labels_dir, Path(im_path).with_suffix('.txt').name)\n",
    "        if not os.path.exists(lbl_path):\n",
    "            open(lbl_path,'w').close()\n",
    "    print(\"Created empty label files for\", len(img_only), \"images.\")\n",
    "else:\n",
    "    print(\"Empty label creation skipped. (set CREATE_EMPTY_LABELS=True to enable)\")\n",
    "\n",
    "# quick fail if too many mismatches\n",
    "if len(img_only) > 0 or len(lbl_only) > 0:\n",
    "    print(\"WARNING: There are unmatched images/labels in TRAIN. You may want to resolve before training.\")\n",
    "else:\n",
    "    print(\"TRAIN image/label counts match exactly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f00630f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected label format for sample: /home/23ucc611/SWE/Poaching/dataset/train/labels/0000015c-a1bb-dffb-a5de-adfb5a640003_4x3_jpg.rf.484d2188a05371551b31bdeeafc3e350.txt\n",
      "Format: obb_8_points\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 ‚Äî Basic label format check: peek at some label files and detect OBB format\n",
    "# OBB YOLOv8 common formats: \n",
    "# - center + w + h + angle: \"cls cx cy w h angle\" (5 floats after cls)\n",
    "# - 8-point polygon: \"cls x1 y1 x2 y2 x3 y3 x4 y4\" (8 floats)\n",
    "# We'll detect which it is.\n",
    "def detect_label_format(sample_label_path):\n",
    "    with open(sample_label_path) as f:\n",
    "        lines = [l.strip() for l in f if l.strip()]\n",
    "    if not lines:\n",
    "        return \"empty\"\n",
    "    parts = lines[0].split()\n",
    "    floats_count = len(parts)-1\n",
    "    if floats_count == 5:\n",
    "        return \"obb_cx_cy_w_h_angle\"\n",
    "    elif floats_count == 8:\n",
    "        return \"obb_8_points\"\n",
    "    elif floats_count == 4:\n",
    "        return \"yolo_xywh\"  # standard axis-aligned\n",
    "    else:\n",
    "        return f\"unknown ({floats_count} coords)\"\n",
    "\n",
    "sample_label = None\n",
    "for p in train_lbls[:5]:\n",
    "    if os.path.getsize(p) > 0:\n",
    "        sample_label = p\n",
    "        break\n",
    "\n",
    "if sample_label:\n",
    "    fmt = detect_label_format(sample_label)\n",
    "    print(\"Detected label format for sample:\", sample_label)\n",
    "    print(\"Format:\", fmt)\n",
    "else:\n",
    "    print(\"No non-empty label file found to detect format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ff20153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN objects: 5020 distinct classes in train: 72\n",
      "VAL objects  : 1079 distinct classes in val: 72\n",
      "\n",
      "Top train classes (id:name:count)\n",
      "30: Humming Bird: 70\n",
      "34: Kangaroo: 70\n",
      "39: Lizard: 70\n",
      "44: Owl: 70\n",
      "32: Hyena: 70\n",
      "36: Koala: 70\n",
      "11: Coyote: 70\n",
      "27: Hippopotamus: 70\n",
      "9: Cheetah: 70\n",
      "8: Car: 70\n",
      "64: Truck: 70\n",
      "33: Jeep: 70\n",
      "68: Wombat: 70\n",
      "43: Otter: 70\n",
      "10: Chimpanzee: 70\n"
     ]
    }
   ],
   "source": [
    "# Cell 10 ‚Äî per-class counts (approx; for OBB we read class id from start of each line)\n",
    "def count_classes(label_paths):\n",
    "    cnt = Counter()\n",
    "    total = 0\n",
    "    for p in label_paths:\n",
    "        with open(p) as f:\n",
    "            for l in f:\n",
    "                l = l.strip()\n",
    "                if not l: continue\n",
    "                parts = l.split()\n",
    "                cls = parts[0]\n",
    "                cnt[int(float(cls))] += 1\n",
    "                total += 1\n",
    "    return total, cnt\n",
    "\n",
    "train_total_objs, train_class_counts = count_classes(train_lbls)\n",
    "val_total_objs,   val_class_counts   = count_classes(val_lbls)\n",
    "print(\"TRAIN objects:\", train_total_objs, \"distinct classes in train:\", len(train_class_counts))\n",
    "print(\"VAL objects  :\", val_total_objs,   \"distinct classes in val:\", len(val_class_counts))\n",
    "\n",
    "# map index -> name if names available\n",
    "if names_list:\n",
    "    # convert names_list to list if dict earlier\n",
    "    names = names_list\n",
    "    print(\"\\nTop train classes (id:name:count)\")\n",
    "    for cls_id, c in train_class_counts.most_common(15):\n",
    "        name = names[cls_id] if cls_id < len(names) else \"<unknown>\"\n",
    "        print(f\"{cls_id}: {name}: {c}\")\n",
    "else:\n",
    "    print(\"No class names found in data.yaml; showing ids only:\")\n",
    "    print(train_class_counts.most_common(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375201e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote /home/23ucc611/SWE/Poaching/dataset/splits_txt/train.txt  -> 4182\n",
      "Wrote /home/23ucc611/SWE/Poaching/dataset/splits_txt/val.txt  -> 905\n",
      "Wrote /home/23ucc611/SWE/Poaching/dataset/splits_txt/test.txt  -> 898\n",
      "Split files created at: /home/23ucc611/SWE/Poaching/dataset/splits_txt\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 ‚Äî create train.txt / val.txt / test.txt with absolute image paths (YOLO likes absolute or relative to data.yaml)\n",
    "OUT_SPLIT_DIR = os.path.join(BASE_DIR, \"splits_txt\")\n",
    "os.makedirs(OUT_SPLIT_DIR, exist_ok=True)\n",
    "\n",
    "def write_split_list(img_list, out_path):\n",
    "    # prefer absolute paths\n",
    "    with open(out_path, 'w') as f:\n",
    "        for p in sorted(img_list):\n",
    "            f.write(str(Path(p).resolve()) + \"\\n\")\n",
    "    print(\"Wrote\", out_path, \" ->\", len(img_list))\n",
    "\n",
    "write_split_list(train_imgs, os.path.join(OUT_SPLIT_DIR, \"train.txt\"))\n",
    "write_split_list(val_imgs, os.path.join(OUT_SPLIT_DIR, \"val.txt\"))\n",
    "if test_imgs:\n",
    "    write_split_list(test_imgs, os.path.join(OUT_SPLIT_DIR, \"test.txt\"))\n",
    "print(\"Split files created at:\", OUT_SPLIT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db1b5f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote absolute-path yaml: /home/23ucc611/SWE/Poaching/dataset/splits_txt/data_abs.yaml\n"
     ]
    }
   ],
   "source": [
    "# Cell 12 ‚Äî optional: create a backup copy of data.yaml that uses absolute paths for train/val/test (safer for CLI)\n",
    "import copy\n",
    "data_abs = copy.deepcopy(data)\n",
    "\n",
    "def abs_path_entry(entry):\n",
    "    if entry is None: return None\n",
    "    p = str(Path(entry))\n",
    "    if not os.path.isabs(p):\n",
    "        p = str(Path(BASE_DIR) / p)\n",
    "    return str(Path(p).resolve())\n",
    "\n",
    "if data.get('train'):\n",
    "    data_abs['train'] = abs_path_entry(data['train'])\n",
    "if data.get('val'):\n",
    "    data_abs['val'] = abs_path_entry(data.get('val') or data.get('valid') or data.get('val'))\n",
    "if data.get('test'):\n",
    "    data_abs['test'] = abs_path_entry(data['test'])\n",
    "\n",
    "ABS_DATA_YAML = os.path.join(OUT_SPLIT_DIR, \"data_abs.yaml\")\n",
    "with open(ABS_DATA_YAML,'w') as f:\n",
    "    yaml.safe_dump(data_abs, f, sort_keys=False)\n",
    "print(\"Wrote absolute-path yaml:\", ABS_DATA_YAML)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ebf9a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run this command in terminal (or prefix with '!' in a notebook cell):\n",
      "\n",
      "yolo obb train model=yolo11s-obb.pt data=/home/23ucc611/SWE/Poaching/dataset/splits_txt/data_abs.yaml epochs=50 imgsz=1024 batch=16 project=poacher_obb name=exp1\n",
      "\n",
      "Notes:\n",
      "- If you run in Colab, prefix the command with '!' and ensure GPU is enabled.\n",
      "- If you get OOM, reduce imgsz or batch size.\n",
      "- Trained weights will be saved under runs/obb/train/{exp_name}/weights/\n"
     ]
    }
   ],
   "source": [
    "# Cell 14 ‚Äî show ready-to-run CLI command (edit epochs/imgsz/batch as needed)\n",
    "# use ABS_DATA_YAML created earlier\n",
    "model_name = \"yolo11s-obb.pt\"   # small OBB pretrained model (change to yolo11s-obb.pt if you want larger)\n",
    "epochs = 50\n",
    "imgsz = 1024   # OBB benefits from higher resolution on oriented objects; reduce if memory limited\n",
    "batch = 16      # lower if OOM\n",
    "project = \"poacher_obb\"\n",
    "exp_name = \"exp1\"\n",
    "\n",
    "cli_cmd = f\"yolo obb train model={model_name} data={ABS_DATA_YAML} epochs={epochs} imgsz={imgsz} batch={batch} project={project} name={exp_name}\"\n",
    "print(\"Run this command in terminal (or prefix with '!' in a notebook cell):\\n\")\n",
    "print(cli_cmd)\n",
    "print(\"\\nNotes:\\n- If you run in Colab, prefix the command with '!' and ensure GPU is enabled.\\n- If you get OOM, reduce imgsz or batch size.\\n- Trained weights will be saved under runs/obb/train/{exp_name}/weights/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457e781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to start training via Python API. This call will block until training finishes (run only if you want to train in this notebook).\n",
      "Model: yolo11s-obb.pt\n",
      "Data yaml: /home/23ucc611/SWE/Poaching/dataset/splits_txt/data_abs.yaml\n",
      "epochs, imgsz, batch: 50 1024 16\n"
     ]
    }
   ],
   "source": [
    "# Cell 15 ‚Äî optional: run training via the Python API (ultralytics) directly from notebook\n",
    "# WARNING: this will start training inside the notebook kernel. Use this if you prefer an in-notebook run.\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"Preparing to start training via Python API. This call will block until training finishes (run only if you want to train in this notebook).\")\n",
    "print(\"Model:\", model_name)\n",
    "print(\"Data yaml:\", ABS_DATA_YAML)\n",
    "print(\"epochs, imgsz, batch:\", epochs, imgsz, batch)\n",
    "\n",
    "# Example: uncomment to run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eacb2c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-obb.pt to 'yolo11s-obb.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 19.0MB 21.8MB/s 0.9s0.9s<0.0ss\n",
      "New https://pypi.org/project/ultralytics/8.3.231 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.229 üöÄ Python-3.10.18 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32494MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/23ucc611/SWE/Poaching/dataset/splits_txt/data_abs.yaml, degrees=0.0, deterministic=True, device=6, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s-obb.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=exp1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=poacher_obb, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/23ucc611/SWE/Poaching/poacher_obb/exp1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=obb, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=72\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1   1133451  ultralytics.nn.modules.head.OBB              [72, 1, [128, 256, 512]]      \n",
      "YOLO11s-obb summary: 196 layers, 9,741,835 parameters, 9,741,819 gradients, 22.7 GFLOPs\n",
      "\n",
      "Transferred 535/541 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 22.7MB/s 0.2s.2s<0.0s.7s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 786.7¬±141.7 MB/s, size: 53.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/23ucc611/SWE/Poaching/dataset/train/labels... 4182 images, 38 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4182/4182 1.4Kit/s 3.0s<0.4s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/23ucc611/SWE/Poaching/dataset/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 665.6¬±225.7 MB/s, size: 42.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/23ucc611/SWE/Poaching/dataset/valid/labels... 905 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 905/905 1.4Kit/s 0.6s<0.3s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/23ucc611/SWE/Poaching/dataset/valid/labels.cache\n",
      "Plotting labels to /home/23ucc611/SWE/Poaching/poacher_obb/exp1/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000132, momentum=0.9) with parameter groups 87 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/23ucc611/SWE/Poaching/poacher_obb/exp1\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      0.93G      1.661      5.717      3.796         26       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 1.7it/s 2:38<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.2it/s 25.6s0.3ss\n",
      "                   all        905       1079    0.00359     0.0253    0.00318    0.00176\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      10.7G      1.306      4.694        3.5         17       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:60<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.7it/s 21.4s0.4ss\n",
      "                   all        905       1079     0.0262       0.37     0.0518     0.0309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      10.8G      1.321       4.03      3.451         23       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.1it/s 2:02<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.0it/s 28.6s0.4ss\n",
      "                   all        905       1079      0.342      0.192      0.113     0.0689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      10.8G      1.288      3.635      3.392         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 2:02<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.2it/s 17.7s0.3s\n",
      "                   all        905       1079      0.336      0.231      0.177      0.115\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50      10.9G      1.277      3.353       3.37         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 2:01<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.2it/s 17.8s0.3s\n",
      "                   all        905       1079      0.462      0.261      0.236      0.156\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      10.9G      1.256      3.124      3.334         23       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:59<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.1it/s 18.5s0.3s\n",
      "                   all        905       1079      0.363      0.309      0.262      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50        11G      1.245      2.966      3.315         14       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:59<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.2it/s 17.6s0.3s\n",
      "                   all        905       1079      0.379      0.335      0.313      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50        11G      1.207      2.795      3.285         24       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:59<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.4it/s 16.9s0.3s\n",
      "                   all        905       1079      0.412      0.334      0.324      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50        11G      1.203      2.675      3.259         17       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 2:02<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.3it/s 17.2s0.3s\n",
      "                   all        905       1079      0.408       0.36      0.366      0.244\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      11.1G      1.172      2.586      3.244         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:57<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.3it/s 17.4s0.3ss\n",
      "                   all        905       1079      0.371      0.409      0.376      0.255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      11.1G      1.164      2.506       3.23         17       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:60<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.2it/s 17.8s0.4s\n",
      "                   all        905       1079      0.434        0.4      0.408      0.283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      11.2G      1.153      2.405      3.237         25       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:59<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.1it/s 18.6s0.3s\n",
      "                   all        905       1079      0.455      0.402       0.43      0.297\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      11.2G       1.14      2.364      3.189         20       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.0it/s 19.2s0.3s\n",
      "                   all        905       1079      0.467      0.437      0.434      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      11.2G      1.136      2.287      3.175         21       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.3it/s 1:56<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.2it/s 17.9s0.3s\n",
      "                   all        905       1079       0.49      0.413      0.455      0.318\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      11.3G      1.114      2.213      3.163         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 2:00<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.1it/s 18.4s0.3s\n",
      "                   all        905       1079      0.497      0.419      0.454      0.315\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      11.3G      1.104      2.171      3.148         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.1it/s 18.7s0.3s\n",
      "                   all        905       1079      0.464      0.491      0.497      0.347\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      11.4G      1.097      2.121      3.145         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:57<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.2it/s 17.7s0.3s\n",
      "                   all        905       1079      0.461      0.478      0.492      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      11.4G      1.095      2.077      3.139         13       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.0it/s 19.0s0.3ss\n",
      "                   all        905       1079      0.495      0.499      0.515      0.365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      11.5G      1.078      2.052      3.126         24       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.1it/s 18.1s0.3s\n",
      "                   all        905       1079      0.529      0.458      0.512      0.356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      11.5G      1.063      1.953      3.124         17       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.2it/s 18.1s0.3s\n",
      "                   all        905       1079      0.498      0.501      0.529      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50      11.5G      1.059      1.966      3.091         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:59<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.9it/s 19.9s0.3ss\n",
      "                   all        905       1079      0.542      0.497       0.53      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50      11.6G      1.072      1.936      3.097         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:57<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.2it/s 17.9s0.4s\n",
      "                   all        905       1079      0.521      0.522      0.551      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50      11.6G      1.047      1.893      3.071         24       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.0it/s 19.2s0.3s\n",
      "                   all        905       1079      0.565      0.528      0.559      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      11.7G      1.035      1.861      3.064         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:57<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.0it/s 19.0s0.3s\n",
      "                   all        905       1079      0.567      0.507       0.55      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      11.7G      1.031      1.812      3.062         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:59<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.0it/s 18.7s0.3ss\n",
      "                   all        905       1079      0.555      0.536      0.572      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      11.8G      1.021      1.806      3.036         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:57<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.1it/s 18.6s0.3s\n",
      "                   all        905       1079      0.532       0.56      0.581      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      11.8G       1.02      1.771      3.061         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.1it/s 18.2s0.4s\n",
      "                   all        905       1079      0.584      0.536      0.587      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      11.8G      1.017      1.737      3.054         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:59<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.9it/s 19.4s0.3s\n",
      "                   all        905       1079      0.583      0.536      0.581      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      11.9G      1.003      1.709      3.036         17       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.2it/s 18.0s0.3s\n",
      "                   all        905       1079      0.575      0.551      0.585      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      11.9G      1.015      1.694      3.036         19       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 2:01<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.1it/s 18.4s0.3s\n",
      "                   all        905       1079      0.588      0.568      0.603      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50        12G     0.9976      1.668      3.028         24       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.1it/s 18.5s0.4s\n",
      "                   all        905       1079       0.57      0.583      0.609      0.437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50        12G     0.9953      1.666      3.033         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:57<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.1it/s 18.4s0.3s\n",
      "                   all        905       1079      0.617      0.565      0.617      0.442\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50        12G     0.9848      1.636      3.028         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:59<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.9it/s 19.7s0.3s\n",
      "                   all        905       1079      0.577      0.589      0.616      0.444\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      12.1G     0.9817      1.608      2.992         19       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:57<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.0it/s 18.7s0.3s\n",
      "                   all        905       1079      0.626      0.562      0.608      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      12.1G     0.9865       1.62      3.029         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.0it/s 18.9s0.3s\n",
      "                   all        905       1079       0.65      0.559      0.628      0.454\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      12.2G     0.9713      1.584      2.993         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:57<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.8it/s 20.0s0.3ss\n",
      "                   all        905       1079      0.608      0.589      0.626      0.449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      12.2G     0.9706      1.561      2.967         17       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.1it/s 18.1s0.3s\n",
      "                   all        905       1079      0.623      0.586      0.634      0.455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      12.3G     0.9638      1.549          3         17       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.9it/s 19.6s0.4s\n",
      "                   all        905       1079      0.636      0.576      0.636      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      12.3G     0.9647      1.549      2.998         13       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.0it/s 18.7s0.3s\n",
      "                   all        905       1079      0.653      0.587      0.642      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      12.3G     0.9663      1.538      2.984         22       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.2it/s 1:58<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.3it/s 17.4s0.3s\n",
      "                   all        905       1079      0.668      0.582      0.648      0.468\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      12.6G     0.7903      1.033      2.611         11       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.1it/s 2:03<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.9it/s 20.0s0.3s\n",
      "                   all        905       1079      0.616      0.584      0.635      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      12.6G     0.7616     0.9409      2.576         10       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.5it/s 1:46<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.8it/s 20.0s0.4s\n",
      "                   all        905       1079      0.653      0.603      0.652      0.474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      12.7G     0.7467     0.9144      2.537          6       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.5it/s 1:46<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.2it/s 17.6s0.4s\n",
      "                   all        905       1079      0.673      0.604      0.656      0.476\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50      12.7G     0.7426     0.8796      2.551          6       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.5it/s 1:45<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.9it/s 19.6s0.4s\n",
      "                   all        905       1079      0.674      0.593      0.656       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50      12.7G     0.7374     0.8656       2.54          7       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.5it/s 1:45<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.0it/s 19.3s0.3s\n",
      "                   all        905       1079      0.667      0.591      0.651      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      12.8G     0.7211     0.8394      2.511          7       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.5it/s 1:46<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.8it/s 20.6s0.3ss\n",
      "                   all        905       1079      0.696      0.604      0.664      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50      12.8G     0.7158     0.8257      2.504          6       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.5it/s 1:45<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.9it/s 19.4s0.4s\n",
      "                   all        905       1079      0.695      0.604      0.668       0.49\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50      12.9G     0.7133      0.809      2.495          8       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.5it/s 1:45<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.9it/s 19.4s0.4ss\n",
      "                   all        905       1079      0.646      0.624      0.664      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50      12.9G     0.7083     0.7953      2.478          6       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.5it/s 1:45<0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.0it/s 19.1s0.4s\n",
      "                   all        905       1079      0.682      0.606      0.671      0.492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50      12.9G     0.7019     0.7842      2.484          6       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 262/262 2.5it/s 1:44<0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 3.0it/s 18.9s0.3s\n",
      "                   all        905       1079      0.681      0.612       0.67      0.493\n",
      "\n",
      "50 epochs completed in 1.912 hours.\n",
      "Optimizer stripped from /home/23ucc611/SWE/Poaching/poacher_obb/exp1/weights/last.pt, 20.3MB\n",
      "Optimizer stripped from /home/23ucc611/SWE/Poaching/poacher_obb/exp1/weights/best.pt, 20.3MB\n",
      "\n",
      "Validating /home/23ucc611/SWE/Poaching/poacher_obb/exp1/weights/best.pt...\n",
      "Ultralytics 8.3.229 üöÄ Python-3.10.18 torch-2.6.0+cu124 CUDA:6 (Tesla V100-SXM2-32GB, 32494MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,726,651 parameters, 0 gradients, 22.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 57/57 2.8it/s 20.7s0.3ss\n",
      "                   all        905       1079      0.678      0.611      0.671      0.493\n",
      "              Antelope          9         15      0.381        0.4      0.408      0.264\n",
      "                Badger         15         15      0.815      0.533      0.602      0.449\n",
      "                   Bat         15         15      0.628        0.6      0.684      0.434\n",
      "                  Bear         12         15      0.655      0.533      0.576      0.471\n",
      "                  Bike         15         15          1      0.396      0.697      0.532\n",
      "             Binocular         15         15      0.574      0.629      0.536      0.388\n",
      "                 Bison         11         15      0.765      0.667      0.789      0.648\n",
      "                  Boar         11         15      0.347      0.467      0.509      0.418\n",
      "                   Car         14         14      0.734      0.929      0.918      0.739\n",
      "               Cheetah         15         15      0.798      0.529      0.752      0.583\n",
      "            Chimpanzee         15         15       0.54      0.784      0.641      0.398\n",
      "                Coyote         15         15      0.481      0.333      0.511      0.427\n",
      "                  Deer         12         15      0.401      0.181      0.324      0.269\n",
      "                   Dog         14         15      0.659      0.388      0.564      0.372\n",
      "                Donkey         11         15      0.465      0.348      0.381      0.262\n",
      "                  Duck         11         15      0.206     0.0667      0.366      0.229\n",
      "                 Eagle         15         15      0.776        0.8      0.916      0.734\n",
      "              Elephant          9         15      0.668        0.8      0.774      0.436\n",
      "              Flamingo          9         15      0.805       0.55      0.748      0.485\n",
      "                   Fox         15         15      0.534      0.733      0.715      0.546\n",
      "               Giraffe         15         15      0.924      0.816      0.939      0.675\n",
      "                  Goat         11         15      0.366      0.309      0.307      0.208\n",
      "                 Goose         15         15      0.711      0.733       0.77      0.587\n",
      "               Gorilla         13         15      0.695      0.607      0.709      0.481\n",
      "                  Hare         10         15      0.621      0.438      0.496      0.403\n",
      "              Hedgehog         15         15      0.907      0.655      0.826      0.674\n",
      "            Helicopter         14         15      0.923      0.805      0.948      0.711\n",
      "          Hippopotamus         13         15      0.822      0.667      0.769       0.58\n",
      "              Hornbill         15         15      0.651        0.6      0.687      0.441\n",
      "                 Horse         13         15      0.433      0.333      0.389      0.297\n",
      "          Humming Bird         13         15      0.956      0.933      0.991      0.819\n",
      "                Hunter         12         15      0.448      0.651       0.41      0.243\n",
      "                 Hyena         13         15       0.95      0.733      0.844      0.645\n",
      "                  Jeep         14         15      0.737          1      0.896      0.776\n",
      "              Kangaroo          9         15      0.728      0.535      0.623      0.396\n",
      "                 Knife         15         15          1      0.192      0.363       0.18\n",
      "                 Koala         13         15      0.727        0.8      0.846      0.582\n",
      "               Leopard         15         15      0.591      0.733      0.797      0.675\n",
      "                  Lion         10         15      0.883        0.8      0.862      0.603\n",
      "                Lizard         15         15      0.546        0.6      0.687      0.424\n",
      "                 Mouse         10         15      0.534      0.667       0.55       0.36\n",
      "                 Okapi         13         15      0.792      0.933      0.909      0.735\n",
      "             Orangutan         12         15      0.825        0.6        0.7      0.499\n",
      "                 Otter         11         15      0.672      0.533       0.56      0.365\n",
      "                   Owl         15         15      0.794      0.733      0.794      0.599\n",
      "                    Ox         11         15      0.349      0.333      0.365      0.271\n",
      "                 Panda         11         15      0.911        0.8      0.846      0.575\n",
      "                Parrot         12         15      0.694        0.6      0.604      0.406\n",
      "                   Pig          3         15      0.264      0.133      0.235      0.145\n",
      "                Pigeon          9         15      0.746        0.4      0.503      0.377\n",
      "                Pistol         14         15      0.633      0.667      0.683      0.436\n",
      "             Porcupine         14         15       0.56        0.8      0.651       0.42\n",
      "                Possum         13         15      0.678      0.733      0.769      0.586\n",
      "               Raccoon         14         15      0.812      0.867      0.859      0.649\n",
      "              Reindeer          9         15      0.538      0.667      0.672      0.561\n",
      "                 Rifle         15         15      0.433      0.333      0.351      0.167\n",
      "             Rinoceros         15         15      0.638      0.533      0.636      0.492\n",
      "                  Rope         15         15      0.615      0.851      0.814      0.584\n",
      "             Sandpiper         13         15       0.85      0.733      0.821       0.66\n",
      "                 Sheep          8         15      0.581      0.187      0.289      0.239\n",
      "                 Snake         12         15       0.49      0.267      0.412      0.255\n",
      "               Sparrow         13         15      0.854      0.733      0.775      0.598\n",
      "              Squirrel         13         15      0.668      0.533      0.632       0.47\n",
      "                 Tiger         14         15      0.857      0.867      0.842       0.64\n",
      "                 Truck         15         15      0.785      0.733       0.77      0.567\n",
      "                Turkey          7         15      0.542      0.533      0.581       0.42\n",
      "                   Van         15         15      0.928          1      0.995      0.859\n",
      "                  Wolf         12         15      0.684        0.6      0.703      0.574\n",
      "                Wombat         13         15      0.716      0.733      0.831      0.676\n",
      "            Woodpecker         14         15      0.753        0.8      0.855      0.651\n",
      "                 X-Bow         15         15      0.926      0.533      0.753      0.419\n",
      "                 Zebra         13         15      0.847      0.933      0.948      0.765\n",
      "Speed: 0.4ms preprocess, 4.7ms inference, 0.0ms loss, 5.8ms postprocess per image\n",
      "Results saved to \u001b[1m/home/23ucc611/SWE/Poaching/poacher_obb/exp1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.OBBMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f0ea3d97610>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0015205,  0.00076025,           0],\n",
       "       [          1,           1,           1, ...,  0.00093844,  0.00046922,           0],\n",
       "       [          1,           1,           1, ...,     0.00429,    0.002145,           0],\n",
       "       ...,\n",
       "       [          1,           1,           1, ...,   0.0079325,   0.0039662,           0],\n",
       "       [          1,           1,           1, ...,     0.00308,     0.00154,           0],\n",
       "       [          1,           1,           1, ...,     0.01274,     0.00637,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.25532,     0.25532,     0.25532, ...,           0,           0,           0],\n",
       "       [    0.25316,     0.25316,     0.25316, ...,           0,           0,           0],\n",
       "       [    0.24779,     0.24779,     0.24779, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [    0.41176,     0.41176,     0.41176, ...,           0,           0,           0],\n",
       "       [    0.44444,     0.44444,     0.44444, ...,           0,           0,           0],\n",
       "       [    0.58333,     0.58333,     0.58333, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[     0.1519,      0.1519,      0.1519, ...,           1,           1,           1],\n",
       "       [    0.15625,     0.15625,     0.15625, ...,           1,           1,           1],\n",
       "       [    0.14286,     0.14286,     0.14286, ...,           1,           1,           1],\n",
       "       ...,\n",
       "       [    0.26415,     0.26415,     0.26415, ...,           1,           1,           1],\n",
       "       [    0.30769,     0.30769,     0.30769, ...,           1,           1,           1],\n",
       "       [    0.42424,     0.42424,     0.42424, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[        0.8,         0.8,         0.8, ...,           0,           0,           0],\n",
       "       [    0.66667,     0.66667,     0.66667, ...,           0,           0,           0],\n",
       "       [    0.93333,     0.93333,     0.93333, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [    0.93333,     0.93333,     0.93333, ...,           0,           0,           0],\n",
       "       [        0.8,         0.8,         0.8, ...,           0,           0,           0],\n",
       "       [    0.93333,     0.93333,     0.93333, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: np.float64(0.49308309000398215)\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.26445,     0.44947,     0.43387,     0.47139,     0.53246,     0.38786,     0.64756,     0.41837,     0.73867,      0.5827,     0.39783,     0.42718,     0.26854,     0.37163,     0.26174,     0.22851,      0.7337,     0.43619,     0.48509,      0.5458,     0.67462,     0.20839,     0.58729,     0.48069,\n",
       "           0.40287,     0.67354,     0.71139,     0.58017,     0.44055,     0.29678,      0.8188,     0.24329,     0.64522,      0.7761,     0.39565,     0.17995,     0.58236,     0.67489,     0.60328,     0.42388,     0.36029,     0.73499,     0.49915,     0.36481,     0.59855,     0.27108,     0.57476,     0.40626,\n",
       "           0.14467,     0.37695,     0.43561,      0.4197,     0.58603,     0.64879,     0.56143,     0.16658,     0.49246,     0.58416,     0.66009,     0.23853,     0.25505,     0.59816,      0.4696,      0.6403,     0.56745,     0.41985,     0.85918,      0.5744,     0.67559,     0.65083,      0.4188,     0.76517])\n",
       "names: {0: 'Antelope', 1: 'Badger', 2: 'Bat', 3: 'Bear', 4: 'Bike', 5: 'Binocular', 6: 'Bison', 7: 'Boar', 8: 'Car', 9: 'Cheetah', 10: 'Chimpanzee', 11: 'Coyote', 12: 'Deer', 13: 'Dog', 14: 'Donkey', 15: 'Duck', 16: 'Eagle', 17: 'Elephant', 18: 'Flamingo', 19: 'Fox', 20: 'Giraffe', 21: 'Goat', 22: 'Goose', 23: 'Gorilla', 24: 'Hare', 25: 'Hedgehog', 26: 'Helicopter', 27: 'Hippopotamus', 28: 'Hornbill', 29: 'Horse', 30: 'Humming Bird', 31: 'Hunter', 32: 'Hyena', 33: 'Jeep', 34: 'Kangaroo', 35: 'Knife', 36: 'Koala', 37: 'Leopard', 38: 'Lion', 39: 'Lizard', 40: 'Mouse', 41: 'Okapi', 42: 'Orangutan', 43: 'Otter', 44: 'Owl', 45: 'Ox', 46: 'Panda', 47: 'Parrot', 48: 'Pig', 49: 'Pigeon', 50: 'Pistol', 51: 'Porcupine', 52: 'Possum', 53: 'Raccoon', 54: 'Reindeer', 55: 'Rifle', 56: 'Rinoceros', 57: 'Rope', 58: 'Sandpiper', 59: 'Sheep', 60: 'Snake', 61: 'Sparrow', 62: 'Squirrel', 63: 'Tiger', 64: 'Truck', 65: 'Turkey', 66: 'Van', 67: 'Wolf', 68: 'Wombat', 69: 'Woodpecker', 70: 'X-Bow', 71: 'Zebra'}\n",
       "nt_per_class: array([15, 15, 15, 15, 15, 15, 15, 15, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15])\n",
       "nt_per_image: array([ 9, 15, 15, 12, 15, 15, 11, 11, 14, 15, 15, 15, 12, 14, 11, 11, 15,  9,  9, 15, 15, 11, 15, 13, 10, 15, 14, 13, 15, 13, 13, 12, 13, 14,  9, 15, 13, 15, 10, 15, 10, 13, 12, 11, 15, 11, 11, 12,  3,  9, 14, 14, 13, 14,  9, 15, 15, 15, 13,  8, 12, 13, 13, 14, 15,  7, 15, 12, 13, 14, 15, 13])\n",
       "results_dict: {'metrics/precision(B)': 0.6780882803632385, 'metrics/recall(B)': 0.6108092557836137, 'metrics/mAP50(B)': 0.6705246501909963, 'metrics/mAP50-95(B)': 0.49308309000398215, 'fitness': 0.49308309000398215}\n",
       "save_dir: PosixPath('/home/23ucc611/SWE/Poaching/poacher_obb/exp1')\n",
       "speed: {'preprocess': 0.44036076985587735, 'inference': 4.7057187503708, 'loss': 0.004104772860503329, 'postprocess': 5.83179005323935}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'obb'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(model_name)\n",
    "model.train(data=ABS_DATA_YAML, epochs=epochs, imgsz=imgsz, batch=batch, project=project, name=exp_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
